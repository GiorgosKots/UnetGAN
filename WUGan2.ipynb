{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XgE5GbYVT5PC"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import grad\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import *\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import gumbel_softmax\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from plot_metrics import plot_jsd, plot_jsd_fred, plot_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewU1zUW1JeFd",
        "outputId": "db07bae7-698d-4ea6-8680-a78383cdde08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sequences: 2600\n",
            "Batch shape: torch.Size([64, 156, 5])\n",
            "Number of batches: 40\n"
          ]
        }
      ],
      "source": [
        "from sequence_encoder import SequenceDataset\n",
        "\n",
        "# Define the file path\n",
        "file_path = r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\AMPdata.txt\"\n",
        "\n",
        "# Create an instance of SequenceDataset\n",
        "dataset = SequenceDataset(file_path)\n",
        "\n",
        "# Print the number of sequences\n",
        "num_sequences = len(dataset)\n",
        "print(\"Number of sequences:\", num_sequences)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "# Use the dataloader in your training loop or other processes\n",
        "for batch in dataloader:\n",
        "    print(\"Batch shape:\", batch.shape)\n",
        "    print(\"Number of batches:\", (len(dataloader)))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseq_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample_and_analyze, save_analysis, analyze_sequences\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mJSD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jsd\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCutMix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_cutmix_mask\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\Documents\\GANs\\Old\\seq_analysis.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "from seq_analysis import sample_and_analyze, save_analysis, analyze_sequences\n",
        "from JSD import jsd\n",
        "from CutMix import create_cutmix_mask\n",
        "from models import Generator_lang, UNetDiscriminator\n",
        "from amp_evaluator import evaluate_amp_batch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Define results directory with absolute path\n",
        "results_dir = r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\"\n",
        "\n",
        "# Create model directories\n",
        "model_save_dir = os.path.join(results_dir, 'saved_models2')\n",
        "jsd_models_dir = os.path.join(model_save_dir, 'best_jsd')\n",
        "orf_models_dir = os.path.join(model_save_dir, 'best_orf')\n",
        "amp_models_dir = os.path.join(model_save_dir, 'best_amp')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(jsd_models_dir, exist_ok=True)\n",
        "os.makedirs(orf_models_dir, exist_ok=True)\n",
        "os.makedirs(amp_models_dir, exist_ok=True)\n",
        "\n",
        "############################## DEFINE #######################################################\n",
        "# Parameters                                                                                \n",
        "n_chars = 5                                                                                 \n",
        "seq_len = 156\n",
        "batch_size = 64\n",
        "hidden_g = 128\n",
        "hidden_d = 128\n",
        "num_epochs = 120\n",
        "lambda_gp = 10  # Gradient penalty coefficient\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator_lang(n_chars, seq_len, batch_size, hidden_g).to(device)\n",
        "discriminator = UNetDiscriminator(n_chars, seq_len, hidden_d).to(device)\n",
        "\n",
        "# Optimizers\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.9, 0.999), weight_decay=1e-5)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.9, 0.999), weight_decay=1e-5)\n",
        "\n",
        "d_scheduler = torch.optim.lr_scheduler.ExponentialLR(d_optimizer, gamma=0.99)\n",
        "g_scheduler = torch.optim.lr_scheduler.ExponentialLR(g_optimizer, gamma=0.99)\n",
        "#############################################################################################\n",
        "\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "def calc_gradient_penalty(discriminator, real_data, fake_data, device, lambda_gp=10):\n",
        "    batch_size = real_data.size(0)\n",
        "    \n",
        "    # Only interpolate between real and fake (remove mixed data interpolation)\n",
        "    alpha = torch.rand(batch_size, 1, 1, device=device)\n",
        "    alpha = alpha.expand_as(real_data)\n",
        "    \n",
        "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
        "    interpolates.requires_grad_(True)\n",
        "    \n",
        "    disc_interpolates, _ = discriminator(interpolates)\n",
        "    \n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=disc_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=torch.ones_like(disc_interpolates),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "    \n",
        "    # Flatten gradients\n",
        "    gradients = gradients.view(batch_size, -1)\n",
        "    gradient_penalty = lambda_gp * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    \n",
        "    return gradient_penalty\n",
        "\n",
        "def discriminator_train(discriminator, real_sequences, fake_sequences, mixed_sequences, mask, optimizer, \n",
        "                        device, lambda_mix=1, lambda_dec=1, lambda_consistency=1, scale=0.1):\n",
        "    # Ensure correct shape\n",
        "    if real_sequences.shape[1] != n_chars:\n",
        "        real_sequences = real_sequences.transpose(1, 2)\n",
        "    if fake_sequences.shape[1] != n_chars:\n",
        "        fake_sequences = fake_sequences.transpose(1, 2)\n",
        "    if mixed_sequences.shape[1] != n_chars:\n",
        "        mixed_sequences = mixed_sequences.transpose(1, 2)\n",
        "\n",
        "    # Get predictions for real and fake data\n",
        "    real_global, real_pixel = discriminator(real_sequences)\n",
        "    fake_global, fake_pixel = discriminator(fake_sequences)\n",
        "    mixed_global, mixed_pixel = discriminator(mixed_sequences)\n",
        "\n",
        "    wasserstein_loss = (\n",
        "        -torch.mean(real_global) +      # Maximize real scores\n",
        "        torch.mean(fake_global)         # Minimize fake scores  \n",
        "        # lambda_mix * torch.mean(mixed_global)  # Mixed: partially real\n",
        "    )\n",
        "\n",
        "    # # Consistency loss for mixed samples\n",
        "    # consistency_loss = torch.mean((mixed_global - \n",
        "    #                   (lambda_mix * real_global + (1-lambda_mix) * fake_global))**2)\n",
        "    \n",
        "    # # Calculate Wasserstein loss\n",
        "    # wasserstein_loss = real_loss + fake_loss + mixed_loss \n",
        "\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    mask = mask.squeeze(-1).unsqueeze(1)  # [batch_size, 1, seq_len]    \n",
        "\n",
        "    # # Calculate unified decoder loss\n",
        "    # dec_loss = -torch.mean(\n",
        "    #     torch.log(real_pixel + 1e-8) + # Real positions should be 1\n",
        "    #     torch.log(1 - fake_pixel + 1e-8) + # Fake positions should be 0\n",
        "    #     mask * torch.log(mixed_pixel + 1e-8) + # Mixed sequences should be treated as real where mask is 1\n",
        "    #     (1 - mask) * torch.log(1 - mixed_pixel + 1e-8) # Mixed sequences should be treated as fake where mask is 0\n",
        "    # ) / 3.0\n",
        "\n",
        "    # Ensure all tensors have matching dimensions\n",
        "    real_pixel = real_pixel.view(real_pixel.size(0), 1, -1)[:, :, :5]\n",
        "    fake_pixel = fake_pixel.view(fake_pixel.size(0), 1, -1)[:, :, :5]\n",
        "    mixed_pixel = mixed_pixel.view(mixed_pixel.size(0), 1, -1)[:, :, :5]\n",
        "\n",
        "    dec_loss = (\n",
        "        criterion(real_pixel, torch.ones_like(real_pixel)) +    # Real → 1\n",
        "        criterion(fake_pixel, torch.zeros_like(fake_pixel)) +   # Fake → 0\n",
        "        criterion(mixed_pixel, mask.float())                     # Mixed → mask\n",
        "    ) / 3.0\n",
        "\n",
        "    # Calculate gradient penalty including mixed sequences\n",
        "    gradient_penalty = calc_gradient_penalty(discriminator, real_sequences, fake_sequences, device)\n",
        "\n",
        "    # Scale the losses\n",
        "    wasserstein_loss = wasserstein_loss * scale  # Scale Wasserstein loss\n",
        "    gradient_penalty = gradient_penalty * scale   # Scale gradient penalty\n",
        "\n",
        "    # Normalize decoder loss and combine losses\n",
        "    normalized_dec_loss = 1 + torch.tanh(dec_loss)  # Normalize decoder loss to be in range [0, 2]\n",
        "    total_d_loss = wasserstein_loss + gradient_penalty * (lambda_dec * dec_loss) #+ lambda_consistency * consistency_loss # Combine losses\n",
        "    \n",
        "    # Update weights\n",
        "    optimizer.zero_grad()\n",
        "    total_d_loss.backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return {\n",
        "        'total_d_loss': total_d_loss.item(),\n",
        "        'wasserstein_loss': wasserstein_loss.item(),\n",
        "        'gradient_penalty': gradient_penalty.item(),\n",
        "        'dec_loss': dec_loss.item(), \n",
        "        'normalized_dec_loss': normalized_dec_loss.item()\n",
        "    }\n",
        "\n",
        "def generator_train(generator, discriminator, batch_size, optimizer, device, lambda_pixel=1, scale=1):\n",
        "    # Generate fake sequences\n",
        "    noise = torch.randn(batch_size, 128, device=device)\n",
        "    fake_sequences = generator(noise) \n",
        "    fake_sequences = fake_sequences.transpose(1, 2) # Shape: [batch_size, n_chars, seq_len]\n",
        "\n",
        "    # Get discriminator predictions\n",
        "    fake_global, fake_pixel = discriminator(fake_sequences)\n",
        "    \n",
        "    pixel_loss = -torch.mean(torch.log(fake_pixel + 1e-8))\n",
        "\n",
        "    normalized_dec_loss = 1 + torch.tanh(fake_pixel.mean())  # Normalize decoder loss to be in range [0, 2]\n",
        "    # Generator loss\n",
        "    g_loss = -torch.mean(fake_global) * scale * (lambda_pixel * normalized_dec_loss)\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return {\n",
        "        'g_loss': g_loss.item(),\n",
        "        'pixel_loss': pixel_loss.item()\n",
        "    }\n",
        "\n",
        "def train(generator, discriminator, dataloader, num_epochs, d_step=5, g_step=1, device=device, \n",
        "          lambda_mix=1, lambda_dec=1, lambda_pixel=1, lambda_consistency=1, scale=0.1):\n",
        "    # Initialize scores\n",
        "    jsd_history = []\n",
        "    amp_history = [] \n",
        "\n",
        "    # Save best models\n",
        "    best_jsd_models = [] \n",
        "    best_orf_models = [] \n",
        "    best_amp_models = []\n",
        "\n",
        "    # Initialize FReD score tracking\n",
        "    # fred_history = []\n",
        "\n",
        "    iteration_losses = {\n",
        "        'total_d_loss': [],\n",
        "        'wasserstein_loss': [],\n",
        "        'gradient_penalty': [],\n",
        "        'total_g_loss': [],\n",
        "        'dec_loss': [],\n",
        "        'normalized_dec_loss': [],\n",
        "        'pixel_loss': []\n",
        "    }\n",
        "\n",
        "    def update_best_models(score, epoch, model, best_list, maximize=False, max_keep=5):\n",
        "        \"\"\"Helper function to update best models list\"\"\"\n",
        "        model_state = model.state_dict()\n",
        "        if len(best_list) < max_keep:\n",
        "            best_list.append((score, epoch, model_state))\n",
        "            best_list.sort(reverse=maximize)\n",
        "        else:\n",
        "            if (maximize and score > best_list[-1][0]) or (not maximize and score < best_list[-1][0]):\n",
        "                best_list[-1] = (score, epoch, model_state)\n",
        "                best_list.sort(reverse=maximize)\n",
        "        return best_list\n",
        "\n",
        "    total_iterations = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        running_losses = {\n",
        "        'total_d_loss': 0,\n",
        "        'wasserstein_loss': 0,\n",
        "        'gradient_penalty': 0,\n",
        "        'total_g_loss': 0,\n",
        "        'dec_loss': 0,\n",
        "        'normalized_dec_loss': 0,\n",
        "        'pixel_loss': 0\n",
        "    }\n",
        "        num_batches = len(dataloader)\n",
        "\n",
        "        current_lambda_mix = min(lambda_mix, epoch/10)\n",
        "\n",
        "        for batch_idx, real_sequences in enumerate(dataloader):\n",
        "            total_iterations += 1\n",
        "            \n",
        "            # Ensure real_sequences has shape [batch_size, n_chars, seq_len]\n",
        "            if real_sequences.shape[1] != n_chars:\n",
        "                real_sequences = real_sequences.transpose(1, 2)\n",
        "            real_sequences = real_sequences.to(device)\n",
        "            batch_size = real_sequences.size(0)\n",
        "\n",
        "            # Generate fake sequences\n",
        "            noise = torch.randn(batch_size, 128, device=device)\n",
        "            fake_sequences = generator(noise).detach()\n",
        "            if fake_sequences.shape[1] != n_chars:\n",
        "                fake_sequences = fake_sequences.transpose(1, 2)\n",
        "\n",
        "            # Create CutMix mask and mixed sequences\n",
        "            mask = create_cutmix_mask(real_sequences, lam=0.8)\n",
        "            mixed_sequences = mask * real_sequences + (1 - mask) * fake_sequences\n",
        "\n",
        "            if mixed_sequences.shape[1] != n_chars:\n",
        "                mixed_sequences = mixed_sequences.transpose(1, 2)\n",
        "\n",
        "            # Train discriminator\n",
        "            d_losses_sum = {'total_d_loss': 0, 'wasserstein_loss': 0, 'gradient_penalty': 0, 'dec_loss': 0, 'normalized_dec_loss': 0}\n",
        "            for _ in range(d_step):\n",
        "                d_losses = discriminator_train(discriminator, real_sequences, fake_sequences, mixed_sequences, mask, \n",
        "                                               d_optimizer, device, current_lambda_mix, lambda_dec, lambda_consistency, scale)\n",
        "                for key in d_losses:\n",
        "                    d_losses_sum[key] += d_losses[key]\n",
        "\n",
        "            d_losses_avg = {k: v / d_step for k, v in d_losses_sum.items()}\n",
        "\n",
        "            # Train generator\n",
        "            g_losses_sum = {'g_loss': 0, 'pixel_loss': 0}\n",
        "            for _ in range(g_step):\n",
        "                g_losses = generator_train(generator, discriminator, batch_size, g_optimizer, device, lambda_pixel, scale)\n",
        "                for key in g_losses:\n",
        "                    g_losses_sum[key] += g_losses[key]\n",
        "\n",
        "            g_losses_avg = {k: v / g_step for k, v in g_losses_sum.items()}\n",
        "\n",
        "            # Update losses\n",
        "            iteration_losses['total_d_loss'].append(d_losses_avg['total_d_loss'])\n",
        "            iteration_losses['wasserstein_loss'].append(d_losses_avg['wasserstein_loss'])\n",
        "            iteration_losses['gradient_penalty'].append(d_losses_avg['gradient_penalty'])\n",
        "            iteration_losses['dec_loss'].append(d_losses_avg['dec_loss'])\n",
        "            iteration_losses['normalized_dec_loss'].append(d_losses_avg['normalized_dec_loss'])\n",
        "            iteration_losses['total_g_loss'].append(g_losses_avg['g_loss'])\n",
        "            iteration_losses['pixel_loss'].append(g_losses_avg['pixel_loss'])\n",
        "\n",
        "            running_losses['total_d_loss'] += d_losses_avg['total_d_loss']\n",
        "            running_losses['wasserstein_loss'] += d_losses_avg['wasserstein_loss']\n",
        "            running_losses['gradient_penalty'] += d_losses_avg['gradient_penalty']\n",
        "            running_losses['dec_loss'] += d_losses_avg.get('dec_loss', 0)\n",
        "            running_losses['normalized_dec_loss'] += d_losses_avg.get('normalized_dec_loss', 0)\n",
        "            running_losses['total_g_loss'] += g_losses_avg['g_loss']\n",
        "            running_losses['pixel_loss'] += g_losses_avg['pixel_loss']\n",
        "\n",
        "            if batch_idx % 41 == 0:\n",
        "                print(f'Batch [{batch_idx+1}/{num_batches}]')\n",
        "                print(f'D_total_loss: {d_losses_avg[\"total_d_loss\"]:.4f}')\n",
        "                print(f'Wasserstein Loss: {d_losses_avg[\"wasserstein_loss\"]:.4f}')\n",
        "                print(f'Gradient Penalty: {d_losses_avg[\"gradient_penalty\"]:.4f}')\n",
        "                print(f'Decoder Loss: {d_losses_avg.get(\"dec_loss\", 0):.4f}')\n",
        "                print(f'Normalized Decoder Loss: {d_losses_avg.get(\"normalized_dec_loss\", 0):.4f}')\n",
        "                print(f'G_total_loss: {g_losses_avg[\"g_loss\"]:.4f}')\n",
        "                print(f'Pixel Loss: {g_losses_avg[\"pixel_loss\"]:.4f}\\n')\n",
        "\n",
        "\n",
        "        # Calculate time for this epoch\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        total_time = time.time() - start_time\n",
        "\n",
        "        # Calculate epoch averages\n",
        "        avg_losses = {k: v / num_batches for k, v in running_losses.items()}\n",
        "\n",
        "        # # Calculate metrics and save best models every epoch\n",
        "        # current_jsd = jsd(generator, dataloader, num_batches=5)\n",
        "        # jsd_history.append(current_jsd)\n",
        "\n",
        "        # # Get generated sequences and analyze them\n",
        "        # generated_seqs = sample_and_analyze(generator, epoch=epoch, device=device)\n",
        "        # save_analysis(generated_seqs, epoch, results_dir='Results2')\n",
        "\n",
        "        # # Analyze sequences to get ORF count\n",
        "        # seq_properties = analyze_sequences(generated_seqs)\n",
        "        # orf_count = seq_properties['valid_orfs']\n",
        "\n",
        "        # ===== EVALUATION SECTION =====\n",
        "        # Generate sequences once for all evaluations\n",
        "        noise = torch.randn(320, 128, device=device)\n",
        "        with torch.no_grad():\n",
        "            generated_sequences = generator(noise)\n",
        "\n",
        "        # Get a batch of real sequences for JSD comparison\n",
        "        real_batch = next(iter(dataloader)).to(device)\n",
        "        if real_batch.size(0) < 320:\n",
        "            # If batch size doesn't match, get multiple batches\n",
        "            real_sequences = []\n",
        "            for batch in dataloader:\n",
        "                real_sequences.append(batch)\n",
        "                if sum(b.size(0) for b in real_sequences) >= 320:\n",
        "                    break\n",
        "            real_batch = torch.cat(real_sequences, dim=0)[:320].to(device)\n",
        "\n",
        "        # Convert to DNA strings using existing function\n",
        "        generated_seqs = sample_and_analyze(pre_generated=generated_sequences, epoch=epoch, device=device)\n",
        "        save_analysis(generated_seqs, epoch, results_dir='Results2')\n",
        "\n",
        "        # Calculate JSD\n",
        "        current_jsd = jsd(real_batch, generated_sequences)\n",
        "        jsd_history.append(current_jsd)\n",
        "\n",
        "        # Analyze sequences to get ORF count\n",
        "        seq_properties = analyze_sequences(generated_seqs)\n",
        "        orf_count = seq_properties['valid_orfs']\n",
        "\n",
        "        # Convert to DNA strings for AMP evaluation (removing padding)\n",
        "        generated_dna_seqs = [seq.replace('P', '') for seq in generated_seqs]\n",
        "\n",
        "        # Evaluate AMP properties\n",
        "        amp_score, amp_details = evaluate_amp_batch(generated_dna_seqs, return_details=True)\n",
        "        amp_history.append(amp_score)\n",
        "\n",
        "        # Update all best models\n",
        "        best_jsd_models = update_best_models(current_jsd, epoch, generator, best_jsd_models, maximize=False)\n",
        "        best_orf_models = update_best_models(orf_count, epoch, generator, best_orf_models, maximize=True)\n",
        "        best_amp_models = update_best_models(amp_details[\"perfect_amp_percentage\"], epoch, generator, best_amp_models, maximize=True) # change amp_score with \n",
        "                                                                                                                                      # amp_details[\"perfect_amp_percentage\"]\n",
        "\n",
        "        # Print epoch averages\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] - Epoch Time: {epoch_time:.2f}s - Total Time: {format_time(total_time)}')\n",
        "        print(f'D_total_loss: {avg_losses[\"total_d_loss\"]:.4f}')\n",
        "        print(f'Wasserstein Loss: {avg_losses[\"wasserstein_loss\"]:.4f}')\n",
        "        print(f'Gradient Penalty: {avg_losses[\"gradient_penalty\"]:.4f}')\n",
        "        print(f'Decoder Loss: {avg_losses[\"dec_loss\"]:.4f}')\n",
        "        print(f'Normalized Decoder Loss: {avg_losses[\"normalized_dec_loss\"]:.4f}')\n",
        "        print(f'G_total_loss: {avg_losses[\"total_g_loss\"]:.4f}')\n",
        "        print(f'Pixel Loss: {avg_losses[\"pixel_loss\"]:.4f}\\n')\n",
        "        print(f'Latest JSD Score: {current_jsd:.4f}')\n",
        "        print(f'AMP Score: {amp_score:.2f}% (Perfect AMPs: {amp_details[\"perfect_amp_percentage\"]:.1f}%)')\n",
        "        print(50 * \"-\")\n",
        "\n",
        "        # Step the schedulers\n",
        "        d_scheduler.step()\n",
        "        g_scheduler.step()\n",
        "\n",
        "    # Save best models at the end of training\n",
        "    for i, (jsd_score, epoch, model_state) in enumerate(best_jsd_models):\n",
        "        save_path = os.path.join(jsd_models_dir, f'generator_jsd_{i+1}_epoch_{epoch}_score_{jsd_score:.4f}.pt')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_state,\n",
        "            'jsd_score': jsd_score\n",
        "        }, save_path)\n",
        "\n",
        "    for i, (orf_count, epoch, model_state) in enumerate(best_orf_models):\n",
        "        save_path = os.path.join(orf_models_dir, f'generator_orf_{i+1}_epoch_{epoch}_count_{orf_count}.pt')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_state,\n",
        "            'orf_count': orf_count\n",
        "        }, save_path)\n",
        "\n",
        "    # Save best AMP models\n",
        "    for i, (amp_score, epoch, model_state) in enumerate(best_amp_models):\n",
        "        save_path = os.path.join(amp_models_dir, f'generator_amp_{i+1}_epoch_{epoch}_score_{amp_score:.2f}.pt')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_state,\n",
        "            'amp_score': amp_score\n",
        "        }, save_path)\n",
        "\n",
        "    return iteration_losses, total_iterations, jsd_history, amp_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "66vS1zaoRl-o",
        "outputId": "8d64ff00-e24c-4ee3-fdc3-761d944e9286",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m iteration_losses, total_iterations, jsd_history, amp_history \u001b[38;5;241m=\u001b[39m train(generator, discriminator, dataloader, num_epochs, d_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m      2\u001b[0m                                                         g_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, lambda_dec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, lambda_pixel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot JSD and AMP\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plot_metrics(iteration_losses, total_iterations, num_epochs, \u001b[38;5;28mlen\u001b[39m(dataloader),\n\u001b[0;32m      6\u001b[0m              jsd_history\u001b[38;5;241m=\u001b[39mjsd_history, amp_history\u001b[38;5;241m=\u001b[39mamp_history,\n\u001b[0;32m      7\u001b[0m              plot_jsd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plot_fred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot_amp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "iteration_losses, total_iterations, jsd_history, amp_history = train(generator, discriminator, dataloader, num_epochs, d_step=3, \n",
        "                                                        g_step=1, device=device, lambda_dec=1, lambda_pixel=1, scale=1)\n",
        "\n",
        "# Plot JSD and AMP\n",
        "plot_metrics(iteration_losses, total_iterations, num_epochs, len(dataloader),\n",
        "             jsd_history=jsd_history, amp_history=amp_history,\n",
        "             plot_jsd=True, plot_fred=False, plot_amp=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generation complete!\n",
            "Found 5893 valid sequences out of 9990 generated\n",
            "Sequences saved in: C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\valid_sequences.fasta\n",
            "Analysis saved in: C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\sequence_analysis.txt\n",
            "Converted 5564 DNA sequences to proteins\n",
            "Protein sequences saved in: C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\valid_sequences_proteins.fasta\n"
          ]
        }
      ],
      "source": [
        "from sequence_generator import generate_and_filter_sequences, convert_dna_fasta_to_protein\n",
        "\n",
        "saved_model_path = r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\saved_models2\\best_amp\\generator_amp_2_epoch_66_score_50.31.pt\"  \n",
        "generator.eval()\n",
        "\n",
        "# Generate sequences and convert to proteins in one go\n",
        "sequences, analysis, dna_file = generate_and_filter_sequences(generator, batch_size=64, num_samples=11270-2*640, count_atg=False, add_atg=False)\n",
        "num_proteins, protein_file = convert_dna_fasta_to_protein(input_fasta=dna_file, add_atg=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage above 0.5 (Random Forest): 49.70%\n",
            "Percentage above 0.8 (Random Forest): 8.22%\n",
            "Percentage above 0.5 (SVM): 37.71%\n",
            "Percentage above 0.8 (SVM): 14.70%\n",
            "Percentage above 0.5 (ANN): 34.47%\n",
            "Percentage above 0.8 (ANN): 15.67%\n",
            "\n",
            "Averages across all models:\n",
            "Average percentage above 0.5: 40.63%\n",
            "Average percentage above 0.8: 12.86%\n"
          ]
        }
      ],
      "source": [
        "from analyze_amp_probabilities import calculate_averages\n",
        "\n",
        "# Actual usage example\n",
        "files = [\n",
        "    r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\CAMPdownload_rf.txt\",\n",
        "    r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\CAMPdownload_svm.txt\",\n",
        "    r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\CAMPdownload_ann.txt\"\n",
        "]\n",
        "\n",
        "model_types = [\n",
        "    \"Random Forest\",\n",
        "    \"SVM\",\n",
        "    \"ANN\"\n",
        "]\n",
        "\n",
        "calculate_averages(files, model_types)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
