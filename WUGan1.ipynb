{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XgE5GbYVT5PC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import grad\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.functional import gumbel_softmax\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from plot_metrics import plot_jsd, plot_jsd_fred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewU1zUW1JeFd",
        "outputId": "db07bae7-698d-4ea6-8680-a78383cdde08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First sequence shape: torch.Size([156, 5])\n",
            "\n",
            "Mapping: {'P': 0, 'A': 1, 'T': 2, 'G': 3, 'C': 4}\n",
            "\n",
            "Number of sequences: 2600\n",
            "\n",
            "Number of batches in the DataLoader: 40\n",
            "Batch shape: torch.Size([64, 156, 5])\n",
            "\n",
            "Sample from batch (showing where P padding is):\n",
            "tensor([1, 2, 3, 1, 1, 3, 1, 1, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, file_path, seq_length=156):\n",
        "        self.seq_length = seq_length\n",
        "        self.sequences = []\n",
        "        self.char_to_idx = {'P': 0, 'A': 1, 'T': 2, 'G': 3, 'C': 4}\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                seq = line.strip().split('\\t')[0] # Remove the '1' and whitespace\n",
        "\n",
        "                if len(seq) < seq_length: # Padding with 'P' \n",
        "                    seq = seq + 'P' * (seq_length - len(seq))\n",
        "                seq = seq[:seq_length]  # Truncate if too long\n",
        "\n",
        "                self.sequences.append(seq)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "\n",
        "        # Create one-hot encoding\n",
        "        one_hot = torch.zeros(self.seq_length, len(self.char_to_idx))\n",
        "        for i, char in enumerate(seq[:self.seq_length]):  # Ensure we don't exceed length\n",
        "            if char in self.char_to_idx:  # Check if character is valid\n",
        "                one_hot[i][self.char_to_idx[char]] = 1\n",
        "            else:\n",
        "                one_hot[i][self.char_to_idx['P']] = 1  # Use padding for unknown chars\n",
        "\n",
        "        return one_hot\n",
        "\n",
        "# Test the dataset\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\AMPdata.txt\"\n",
        "    dataset = SequenceDataset(file_path)\n",
        "\n",
        "    # Print first sequence\n",
        "    first_seq = dataset[0]\n",
        "    print(\"First sequence shape:\", first_seq.shape)\n",
        "    print(\"\\nMapping:\", dataset.char_to_idx)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "    print('\\nNumber of sequences:', len(dataloader.dataset))\n",
        "    print(\"\\nNumber of batches in the DataLoader:\", len(dataloader))\n",
        "    # Check a batch\n",
        "    for batch in dataloader:\n",
        "        print(\"Batch shape:\", batch.shape)\n",
        "        print(\"\\nSample from batch (showing where P padding is):\")\n",
        "        print(torch.argmax(batch[0], dim=1)[:10])  \n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IikYW4i9foMU"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, hidden):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.res_block = nn.Sequential(\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv1d(hidden, hidden, 5, padding=2),#nn.Linear(DIM, DIM),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv1d(hidden, hidden, 5, padding=2),#nn.Linear(DIM, DIM),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.res_block(input)\n",
        "        return input + (0.3*output)\n",
        "    \n",
        "class Generator_lang(nn.Module):\n",
        "    def __init__(self, n_chars, seq_len, batch_size, hidden):\n",
        "        super(Generator_lang, self).__init__()\n",
        "        self.fc1 = nn.Linear(128, hidden*seq_len)\n",
        "        self.block = nn.Sequential(\n",
        "            ResBlock(hidden),\n",
        "            ResBlock(hidden),\n",
        "            ResBlock(hidden),\n",
        "            ResBlock(hidden),\n",
        "            ResBlock(hidden),\n",
        "        )\n",
        "        self.conv1 = nn.Conv1d(hidden, n_chars, 1)\n",
        "        self.n_chars = n_chars\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden = hidden\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output = self.fc1(noise)\n",
        "        output = output.view(-1, self.hidden, self.seq_len) # (BATCH_SIZE, DIM, SEQ_LEN)\n",
        "        output = self.block(output)\n",
        "        output = self.conv1(output)\n",
        "        output = output.transpose(1, 2)\n",
        "        shape = output.size()\n",
        "        output = output.contiguous()\n",
        "        output = output.view(self.batch_size*self.seq_len, -1)\n",
        "        output = gumbel_softmax(output, 0.5)\n",
        "        return output.view(shape) # (BATCH_SIZE, SEQ_LEN, len(charmap))\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownBlock, self).__init__()\n",
        "        self.res_block = ResBlock(in_channels)\n",
        "        self.down_block = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.res_block(input)\n",
        "        return self.down_block(x)\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, output_padding=0):\n",
        "        super(UpBlock, self).__init__()\n",
        "        self.res_block = ResBlock(in_channels)\n",
        "        self.up_block = nn.Sequential(\n",
        "            nn.ConvTranspose1d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, output_padding=output_padding),\n",
        "            nn.ReLU(inplace=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.res_block(input)\n",
        "        return self.up_block(x)\n",
        "\n",
        "class UNetDiscriminator(nn.Module):\n",
        "    def __init__(self, n_chars, seq_len, hidden):\n",
        "        super(UNetDiscriminator, self).__init__()\n",
        "        self.n_chars = n_chars\n",
        "        self.seq_len = seq_len\n",
        "        self.hidden = hidden\n",
        "\n",
        "        # self.conv1d = nn.Conv1d(n_chars, hidden, 1)\n",
        "\n",
        "        # Downsampling path\n",
        "        self.down1 = DownBlock(n_chars, hidden)\n",
        "        self.down2 = DownBlock(hidden, hidden * 2)\n",
        "        self.down3 = DownBlock(hidden * 2, hidden * 4)\n",
        "        self.down4 = DownBlock(hidden * 4, hidden * 8)\n",
        "        self.down5 = DownBlock(hidden * 8, hidden * 16)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = ResBlock(hidden * 16)\n",
        "\n",
        "        # Global output layer\n",
        "        self.global_output_layer = nn.Linear(hidden * 16 * (seq_len // 32), 1)\n",
        "\n",
        "        # Upsampling path\n",
        "        self.up1 = UpBlock(hidden * 16, hidden * 8, output_padding=1)\n",
        "        self.up2 = UpBlock(hidden * 8, hidden * 4, output_padding=1)\n",
        "        self.up3 = UpBlock(hidden * 4, hidden * 2, output_padding=1)\n",
        "        self.up4 = UpBlock(hidden * 2, hidden)\n",
        "        self.up5 = UpBlock(hidden, n_chars)\n",
        "\n",
        "        # Pixel-wise output layer\n",
        "        self.pixel_output_layer = nn.Conv1d(n_chars, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Convert to [batch, n_chars, seq_len] for conv1d\n",
        "        if input.shape[1] == self.seq_len:\n",
        "            input = input.transpose(1, 2) \n",
        "        # x = self.conv1d(input)\n",
        "\n",
        "        # Downsampling path\n",
        "        d1 = self.down1(input)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(d5)\n",
        "\n",
        "        # Global output\n",
        "        global_output = b.view(-1, self.hidden * 16 * (self.seq_len // 32))\n",
        "        global_output = self.global_output_layer(global_output)\n",
        "\n",
        "        # Upsampling path\n",
        "        u1 = self.up1(b)\n",
        "        u2 = self.up2(u1)\n",
        "        u3 = self.up3(u2)\n",
        "        u4 = self.up4(u3)\n",
        "        u5 = self.up5(u4)\n",
        "\n",
        "        # Pixel-wise output\n",
        "        pixel_output = self.pixel_output_layer(u5)\n",
        "        pixel_output = torch.sigmoid(pixel_output)\n",
        "        pixel_output = pixel_output.transpose(1, 2) # Back to [batch, seq_len, 1]\n",
        "\n",
        "        return global_output, pixel_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEedmTAtQsLw",
        "outputId": "e67f01ad-d89c-4d34-8a37-55e22b1bed2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from seq_analysis import sample_and_analyze, save_analysis, analyze_sequences\n",
        "from JSD import jsd\n",
        "\n",
        "# Define results directory with absolute path\n",
        "results_dir = r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\"\n",
        "\n",
        "# Create model directories\n",
        "model_save_dir = os.path.join(results_dir, 'saved_models')\n",
        "jsd_models_dir = os.path.join(model_save_dir, 'best_jsd')\n",
        "orf_models_dir = os.path.join(model_save_dir, 'best_orf')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(jsd_models_dir, exist_ok=True)\n",
        "os.makedirs(orf_models_dir, exist_ok=True)\n",
        "\n",
        "############################## DEFINE #######################################################\n",
        "# Parameters                                                                                \n",
        "n_chars = 5                                                                                 \n",
        "seq_len = 156\n",
        "batch_size = 64\n",
        "hidden_g = 194\n",
        "hidden_d = 194\n",
        "num_epochs = 50\n",
        "lambda_gp = 10  # Gradient penalty coefficient\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator_lang(n_chars, seq_len, batch_size, hidden_g).to(device)\n",
        "discriminator = UNetDiscriminator(n_chars, seq_len, hidden_d).to(device)\n",
        "\n",
        "# Optimizers\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.9, 0.999))\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.00005, betas=(0.9, 0.999))\n",
        "\n",
        "#############################################################################################\n",
        "\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "def calc_gradient_penalty(discriminator, real_data, fake_data, device, lambda_gp=lambda_gp):\n",
        "    batch_size = real_data.size(0)\n",
        "\n",
        "    # Random weight term for interpolation between real and fake data\n",
        "    alpha = torch.rand(batch_size, 1, 1, device=device)\n",
        "    alpha = alpha.expand_as(real_data)\n",
        "\n",
        "    # Interpolate between real and fake data\n",
        "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
        "    interpolates = interpolates.requires_grad_(True)\n",
        "\n",
        "    # Calculate discriminator's output for interpolated data\n",
        "    disc_interpolates, _ = discriminator(interpolates)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = grad(\n",
        "        outputs=disc_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=torch.ones_like(disc_interpolates),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    # Calculate gradient penalty\n",
        "    gradient_penalty = lambda_gp * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "\n",
        "    return gradient_penalty\n",
        "\n",
        "def discriminator_train(discriminator, real_sequences, fake_sequences, optimizer, device):\n",
        "    if real_sequences.shape[1] != n_chars:\n",
        "        real_sequences = real_sequences.transpose(1, 2)\n",
        "    if fake_sequences.shape[1] != n_chars:\n",
        "        fake_sequences = fake_sequences.transpose(1, 2)\n",
        "\n",
        "    # Get predictions for real and fake data\n",
        "    real_global, real_pixel = discriminator(real_sequences)\n",
        "    fake_global, fake_pixel = discriminator(fake_sequences)\n",
        "\n",
        "    # Calculate Wasserstein loss\n",
        "    loss = -(torch.mean(real_global) - torch.mean(fake_global))\n",
        "\n",
        "    # Calculate pixel-wise loss\n",
        "    dec_loss = -torch.mean(\n",
        "        torch.log(real_pixel + 1e-8) + # Real positions should be 1\n",
        "        torch.log(1 - fake_pixel + 1e-8))\n",
        "\n",
        "    # Calculate gradient penalty\n",
        "    gradient_penalty = calc_gradient_penalty(discriminator, real_sequences, fake_sequences, device)\n",
        "    loss += gradient_penalty\n",
        "    loss = loss * dec_loss  # Combine losses\n",
        "    \n",
        "    # Update weights\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return {\n",
        "        'loss': loss.item(),\n",
        "        'gradient_penalty': gradient_penalty.item(),\n",
        "        'dec_loss': dec_loss.item()\n",
        "    }\n",
        "\n",
        "def generator_train(generator, discriminator, batch_size, optimizer, device):\n",
        "    # Generate fake sequences\n",
        "    noise = torch.randn(batch_size, 128, device=device)\n",
        "    fake_sequences = generator(noise) \n",
        "    fake_sequences = fake_sequences.transpose(1, 2) # Shape: [batch_size, n_chars, seq_len]\n",
        "\n",
        "    # Get discriminator predictions\n",
        "    fake_global, fake_pixel = discriminator(fake_sequences)\n",
        "\n",
        "    # Generator loss\n",
        "    g_loss = -torch.mean(fake_global)\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return {\n",
        "        'g_loss': g_loss.item()\n",
        "    }\n",
        "\n",
        "def train(generator, discriminator, dataloader, num_epochs, d_step=5, g_step=1, device=device):\n",
        "    # Initialize JSD score\n",
        "    jsd_history = []\n",
        "    best_jsd_models = []  # Will store tuples of (jsd_score, epoch, model_state)\n",
        "    best_orf_models = []  # Will store tuples of (orf_count, epoch, model_state)\n",
        "\n",
        "    # Initialize FReD score tracking\n",
        "    # fred_history = []\n",
        "\n",
        "    iteration_losses = {\n",
        "        'total_d_loss': [],\n",
        "        'gradient_penalty': [],\n",
        "        'total_g_loss': [],\n",
        "        'dec_loss' : []\n",
        "    }\n",
        "\n",
        "    def update_best_models(score, epoch, model, best_list, maximize=False, max_keep=5):\n",
        "        \"\"\"Helper function to update best models list\"\"\"\n",
        "        model_state = model.state_dict()\n",
        "        if len(best_list) < max_keep:\n",
        "            best_list.append((score, epoch, model_state))\n",
        "            best_list.sort(reverse=maximize)\n",
        "        else:\n",
        "            if (maximize and score > best_list[-1][0]) or (not maximize and score < best_list[-1][0]):\n",
        "                best_list[-1] = (score, epoch, model_state)\n",
        "                best_list.sort(reverse=maximize)\n",
        "        return best_list\n",
        "\n",
        "    total_iterations = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        running_losses = {\n",
        "            'total_d_loss': 0,\n",
        "            'gradient_penalty': 0,\n",
        "            'total_g_loss': 0,\n",
        "            'dec_loss': 0\n",
        "        }\n",
        "        num_batches = len(dataloader)\n",
        "\n",
        "        for batch_idx, real_sequences in enumerate(dataloader):\n",
        "            total_iterations += 1\n",
        "            \n",
        "            # Ensure real_sequences has shape [batch_size, n_chars, seq_len]\n",
        "            if real_sequences.shape[1] != n_chars:\n",
        "                real_sequences = real_sequences.transpose(1, 2)\n",
        "            real_sequences = real_sequences.to(device)\n",
        "            batch_size = real_sequences.size(0)\n",
        "\n",
        "            # Train discriminator\n",
        "            d_losses_sum = {'loss': 0, 'gradient_penalty': 0, 'dec_loss': 0}\n",
        "            for _ in range(d_step):\n",
        "                noise = torch.randn(batch_size, 128, device=device)\n",
        "                fake_sequences = generator(noise).detach()  # Detach here\n",
        "                \n",
        "                d_losses = discriminator_train(discriminator, real_sequences, fake_sequences, d_optimizer, device)\n",
        "                for key in d_losses:\n",
        "                    d_losses_sum[key] += d_losses[key]\n",
        "\n",
        "            d_losses_avg = {k: v / d_step for k, v in d_losses_sum.items()}\n",
        "\n",
        "            # Train generator\n",
        "            g_losses_sum = {'g_loss': 0}\n",
        "            for _ in range(g_step):\n",
        "                g_losses = generator_train(generator, discriminator, batch_size, g_optimizer, device)\n",
        "                for key in g_losses:\n",
        "                    g_losses_sum[key] += g_losses[key]\n",
        "\n",
        "            g_losses_avg = {k: v / g_step for k, v in g_losses_sum.items()}\n",
        "\n",
        "            # Update losses\n",
        "            iteration_losses['total_d_loss'].append(d_losses_avg['loss'])\n",
        "            iteration_losses['gradient_penalty'].append(d_losses_avg['gradient_penalty'])\n",
        "            iteration_losses['dec_loss'].append(d_losses_avg['dec_loss'])\n",
        "            iteration_losses['total_g_loss'].append(g_losses_avg['g_loss'])\n",
        "\n",
        "            running_losses['total_d_loss'] += d_losses_avg['loss']\n",
        "            running_losses['gradient_penalty'] += d_losses_avg['gradient_penalty']\n",
        "            running_losses['dec_loss'] += d_losses_avg.get('dec_loss', 0)\n",
        "            running_losses['total_g_loss'] += g_losses_avg['g_loss']\n",
        "\n",
        "            if batch_idx % 20 == 0:\n",
        "                print(f'Batch [{batch_idx+1}/{num_batches}]')\n",
        "                print(f'D_total_loss: {d_losses_avg[\"loss\"]:.4f}')\n",
        "                print(f'Gradient Penalty: {d_losses_avg[\"gradient_penalty\"]:.4f}')\n",
        "                print(f'Decoder Loss: {d_losses_avg.get(\"dec_loss\", 0):.4f}')\n",
        "                print(f'G_total_loss: {g_losses_avg[\"g_loss\"]:.4f}\\n')\n",
        "\n",
        "        # Calculate time for this epoch\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        total_time = time.time() - start_time\n",
        "\n",
        "        # Calculate epoch averages\n",
        "        avg_losses = {k: v / num_batches for k, v in running_losses.items()}\n",
        "\n",
        "        # Calculate metrics and save best models every epoch\n",
        "        current_jsd = jsd(generator, dataloader, num_batches=5)\n",
        "        jsd_history.append(current_jsd)\n",
        "\n",
        "        # Get generated sequences and analyze them\n",
        "        generated_seqs = sample_and_analyze(generator, epoch=epoch, device=device)\n",
        "        save_analysis(generated_seqs, epoch)\n",
        "\n",
        "        # Analyze sequences to get ORF count\n",
        "        seq_properties = analyze_sequences(generated_seqs)\n",
        "        orf_count = seq_properties['valid_orfs']\n",
        "\n",
        "        # Update best models\n",
        "        best_jsd_models = update_best_models(\n",
        "            current_jsd, \n",
        "            epoch, \n",
        "            generator, \n",
        "            best_jsd_models, \n",
        "            maximize=False  # We want to minimize JSD\n",
        "        )\n",
        "\n",
        "        best_orf_models = update_best_models(\n",
        "            orf_count,  # Use the ORF count from analysis\n",
        "            epoch, \n",
        "            generator, \n",
        "            best_orf_models, \n",
        "            maximize=True  # We want to maximize ORF count\n",
        "        )\n",
        "\n",
        "        # Print epoch averages\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] - Epoch Time: {epoch_time:.2f}s - Total Time: {format_time(total_time)}')\n",
        "        print(f'D_total_loss: {avg_losses[\"total_d_loss\"]:.4f}')\n",
        "        print(f'Gradient Penalty: {avg_losses[\"gradient_penalty\"]:.4f}')\n",
        "        print(f'Decoder Loss: {avg_losses[\"dec_loss\"]:.4f}')\n",
        "        print(f'G_total_loss: {avg_losses[\"total_g_loss\"]:.4f}\\n')\n",
        "        print(f'Latest JSD Score: {current_jsd:.4f}')\n",
        "        print(50 * \"-\")\n",
        "\n",
        "    # Save best models at the end of training\n",
        "    for i, (jsd_score, epoch, model_state) in enumerate(best_jsd_models):\n",
        "        save_path = os.path.join(jsd_models_dir, f'generator_jsd_{i+1}_epoch_{epoch}_score_{jsd_score:.4f}.pt')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_state,\n",
        "            'jsd_score': jsd_score\n",
        "        }, save_path)\n",
        "\n",
        "    for i, (orf_count, epoch, model_state) in enumerate(best_orf_models):\n",
        "        save_path = os.path.join(orf_models_dir, f'generator_orf_{i+1}_epoch_{epoch}_count_{orf_count}.pt')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_state,\n",
        "            'orf_count': orf_count\n",
        "        }, save_path)\n",
        "\n",
        "    return iteration_losses, total_iterations, jsd_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "66vS1zaoRl-o",
        "outputId": "8d64ff00-e24c-4ee3-fdc3-761d944e9286",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m iteration_losses, total_iterations, jsd_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plot_jsd(\n\u001b[0;32m      5\u001b[0m     iteration_losses\u001b[38;5;241m=\u001b[39miteration_losses,\n\u001b[0;32m      6\u001b[0m     jsd_history\u001b[38;5;241m=\u001b[39mjsd_history,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     dataloader_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[0;32m     10\u001b[0m )\n",
            "Cell \u001b[1;32mIn[14], line 182\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(generator, discriminator, dataloader, num_epochs, d_step, g_step, device)\u001b[0m\n\u001b[0;32m    179\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m128\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    180\u001b[0m fake_sequences \u001b[38;5;241m=\u001b[39m generator(noise)\u001b[38;5;241m.\u001b[39mdetach()  \u001b[38;5;66;03m# Detach here\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m d_losses \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m d_losses:\n\u001b[0;32m    184\u001b[0m     d_losses_sum[key] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_losses[key]\n",
            "Cell \u001b[1;32mIn[14], line 79\u001b[0m, in \u001b[0;36mdiscriminator_train\u001b[1;34m(discriminator, real_sequences, fake_sequences, optimizer, device)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Get predictions for real and fake data\u001b[39;00m\n\u001b[0;32m     78\u001b[0m real_global, real_pixel \u001b[38;5;241m=\u001b[39m discriminator(real_sequences)\n\u001b[1;32m---> 79\u001b[0m fake_global, fake_pixel \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Calculate Wasserstein loss\u001b[39;00m\n\u001b[0;32m     82\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmean(real_global) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(fake_global))\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[12], line 124\u001b[0m, in \u001b[0;36mUNetDiscriminator.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Upsampling path\u001b[39;00m\n\u001b[0;32m    123\u001b[0m u1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(b)\n\u001b[1;32m--> 124\u001b[0m u2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m u3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup3(u2)\n\u001b[0;32m    126\u001b[0m u4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup4(u3)\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[12], line 68\u001b[0m, in \u001b[0;36mUpBlock.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_block(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\kotsgeo\\AppData\\Local\\Anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:974\u001b[0m, in \u001b[0;36mConvTranspose1d.forward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    964\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    965\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    967\u001b[0m     output_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m )\n\u001b[1;32m--> 974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "iteration_losses, total_iterations, jsd_history = train(generator, discriminator, dataloader, num_epochs, device=device)\n",
        "\n",
        "\n",
        "plot_jsd(\n",
        "    iteration_losses=iteration_losses,\n",
        "    jsd_history=jsd_history,\n",
        "    total_iterations=total_iterations,\n",
        "    num_epochs=num_epochs,\n",
        "    dataloader_size=len(dataloader)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 80000/100032 sequences. Found 7721 valid sequences so far.\n",
            "\n",
            "Generation complete!\n",
            "Found 9688 valid sequences out of 100032 generated\n",
            "Sequences saved in: C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\valid_sequences.fasta\n",
            "Analysis saved in: C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\sequence_analysis.txt\n",
            "Converted 9688 DNA sequences to proteins\n",
            "Protein sequences saved in: C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\valid_sequences_proteins.fasta\n"
          ]
        }
      ],
      "source": [
        "from sequence_generator import generate_and_filter_sequences, convert_dna_fasta_to_protein\n",
        "\n",
        "saved_model_path = r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\saved_models\\best_orf\\generator_orf_1_epoch_49_count_28.pt\"  \n",
        "generator.eval()\n",
        "\n",
        "# Generate sequences and convert to proteins in one go\n",
        "sequences, analysis, dna_file = generate_and_filter_sequences(generator, num_samples=100032,add_atg=False)\n",
        "num_proteins, protein_file = convert_dna_fasta_to_protein(input_fasta=dna_file, add_atg=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage above 0.5 (Random Forest): 29.13%\n",
            "Percentage above 0.8 (Random Forest): 5.99%\n",
            "Percentage above 0.5 (SVM): 28.24%\n",
            "Percentage above 0.8 (SVM): 6.86%\n",
            "Percentage above 0.5 (ANN): 18.33%\n",
            "Percentage above 0.8 (ANN): 6.41%\n",
            "\n",
            "Averages across all models:\n",
            "Average percentage above 0.5: 25.23%\n",
            "Average percentage above 0.8: 6.42%\n"
          ]
        }
      ],
      "source": [
        "from analyze_amp_probabilities import calculate_averages\n",
        "\n",
        "# Actual usage example\n",
        "files = [\n",
        "    r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\CAMPdownload_rf.txt\",\n",
        "    r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\CAMPdownload_svm.txt\",\n",
        "    r\"C:\\Users\\kotsgeo\\Documents\\GANs\\Old\\campr4\\CAMPdownload_ann.txt\"\n",
        "]\n",
        "\n",
        "model_types = [\n",
        "    \"Random Forest\",\n",
        "    \"SVM\",\n",
        "    \"ANN\"\n",
        "]\n",
        "\n",
        "calculate_averages(files, model_types)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
